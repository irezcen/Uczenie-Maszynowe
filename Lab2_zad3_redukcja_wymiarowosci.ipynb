{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W poprzednich dwóch zadaniach ekstrahowaliśmy cechy z sygnału podzielonego na ramki, uzyskując obraz (macierz 2D) opisujący sygnał. Jest to bardzo często stosowane w analizie sygnałów podejście, ale nie jedyne.\n",
    "\n",
    "Z sygnałów można też ekstrahować inne parametry, np. parametry czasowe sygnału (częstotliwość przejść przez zero, środek ciężkości sygnału), parametry widmowe (momenty widmowe, kurtoza i skośność widma), parametry formantowe (częstotliwości formantów, stosunek ich amplitud) i wiele innych. Zbiór różnych parametrów sygnałów, które dają bardzo dobre rezultaty w klasyfikacji sygnałów akustycznych jest zawarty w bibliotece OpenSMILE.\n",
    "\n",
    "Jeżeli użyjemy najnowszej wersji tej bilbioteki do ekstrakcji cech, uzyskamy  6373 parametry opisujące pojedynczy sygnał (osoby zainteresowane mogę doczytać, jakie dokładnie są to cechy https://audeering.github.io/opensmile/about.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import opensmile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "feats = smile.process_file('dane_testowe/1-phrase.wav') #feats od ang. features - cechy\n",
    "feats1 = smile.process_file('dane_testowe/10-phrase.wav')\n",
    "feats = pd.concat([feats, feats1])\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponownie wykorzystując napisany wcześniej kod, wylicz parametry wszystkich sygnałów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "\n",
    "from os import listdir\n",
    "pliki = listdir('dane_testowe/')\n",
    "pliki = ['dane_testowe/'+x for x in pliki]\n",
    "Phrases = []\n",
    "pliki.sort()\n",
    "#for i in pliki:\n",
    "#    x, fs = librosa.load(i)\n",
    "#   data = x\n",
    "#    a = data.flatten()\n",
    "#    a = a.transpose()\n",
    "#    Phrases.append(a)\n",
    "#min_length = min(map(lambda x: x.shape[-1], Phrases))\n",
    "#Phrases = np.stack([x[..., :min_length] for x in Phrases])\n",
    "feats = []\n",
    "for i in pliki:\n",
    "    feats.append(smile.process_file(i))\n",
    "feats = pd.concat(feats)\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed przystąpieniem do selekcji cech i uczenia klasyfikatora, dane należy najpierw ustandaryzować. Można to zrobić np. używając funkcji StandardScaler z bilbioteki sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "\n",
    "Zachowujemy kolejność:\n",
    "1. wyznaczenie średniej i wariancji/odchylenia standardowego zbioru uczącego, które będą wykorzystane do standaryzacji\n",
    "2. standaryzacja zbioru uczącego: \n",
    "3. standaryzacja zbioru testowego w oparciu o parametry ze zbioru testowego (czyli średnia i wariancja/odchylenie standardowe używane do standaryzacji zbioru testowego są wyliczane na zbiorze uczącym - w ten sposób wszystkie dane są przekształcane jednakowo): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "labels = []\n",
    "for i in pliki:\n",
    "    if i.__contains__('phrase'):\n",
    "        labels.append(1)\n",
    "        continue\n",
    "    labels.append(0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#print(labels)\n",
    "#print(pliki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na ustandaryzowanych danych wytrenuj klasyfikator i wylicz metryki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "scaler = StandardScaler()\n",
    "def test():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "    #scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf.predict(X_test), Y_test\n",
    "\n",
    "good = 0\n",
    "bad = 0\n",
    "test_size = 100\n",
    "tic = time.perf_counter()\n",
    "for i in range(0, test_size):\n",
    "    p, t = test()\n",
    "    for j in range(0, len(p)):\n",
    "        if p[j] == t[j]:\n",
    "            good=good+1\n",
    "            continue\n",
    "        bad = bad+1\n",
    "toc = time.perf_counter()\n",
    "print('sukces: '+ str(good/(good+bad)))\n",
    "print(' time: '+ str(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6373 cechy opisujące jeden sygnał to dość dużo. Żeby zmniejszyć liczbę tych cech należy zastosować jedną z metod redukcji wymiarowości. Wpłynie to na zmniejszenie skomplikowania niektórych rodzajów klasyfikatorów, przyspieszy proces uczenia i pozwoli zmniejszyć przeuczenie modelu.\n",
    "\n",
    "Zaczniemy od metody bazującej na wartości F z ANOVY. W bibliotece sklearn jest to funkcja SelectKBest(): https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest#sklearn.feature_selection.SelectKBest\n",
    "\n",
    "Wybierz liczbę cech, które chcesz zachować. Funkcja wybierze ze wszystkich 6373 cech tylko tyle, ile sprecyzujesz w taki sposób, by jak najlepiej opisywać zmienność i różnicować obiekty.\n",
    "\n",
    "Liczbę cech można optymalizować, ale tym zajmiemy się kiedy indziej. Dzisiaj spróbuj ręcznie dobrać ich liczbę tak, by wyniki klasyfikacji były zadowalające."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "\n",
    "liczba_cech = 50\n",
    "selector = SelectKBest(k=liczba_cech)\n",
    "#X_train\n",
    "X_train_Kbest = selector.fit_transform(X_train, Y_train)\n",
    "X_test_Kbest = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenuj klasyfikator na zredukowanej liczbie cech. Jakie wartości metryk wyszły teraz? Czy są gorsze niż wcześniej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_k():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "    #selector = SelectKBest(k=10)\n",
    "    X_train_Kbest = selector.fit_transform(X_train, Y_train)\n",
    "    X_test_Kbest = selector.transform(X_test)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train_Kbest, Y_train)\n",
    "    return clf.predict(X_test_Kbest), Y_test\n",
    "\n",
    "good = 0\n",
    "bad = 0\n",
    "test_size = 100\n",
    "tic = time.perf_counter()\n",
    "for i in range(0, test_size):\n",
    "    p, t = test_k()\n",
    "    for j in range(0, len(p)):\n",
    "        if p[j] == t[j]:\n",
    "            good=good+1\n",
    "            continue\n",
    "        bad = bad+1\n",
    "toc = time.perf_counter()\n",
    "print('sukces: '+ str(good/(good+bad)))\n",
    "print(' time: '+ str(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejną funkcją wartą poznania jest metoda bardzo podobna do SelectKBest, czyli SelectPercentile. Działa na tej samej zasadzie, ale zamiast określać konkretną liczbę cech, które chcemy zachować, określamy jaka część cech ma być zachowana, np. 0.4 (40%).\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "\n",
    "percentile = 0.2\n",
    "selector = SelectPercentile(percentile=percentile)\n",
    "#X_train\n",
    "X_train_perc = selector.fit_transform(X_train, Y_train)\n",
    "X_test_perc = selector.transform(X_test)\n",
    "\n",
    "def test_p():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "    #selector = SelectPercentile(percentile=percentile)\n",
    "    X_train_perc = selector.fit_transform(X_train, Y_train)\n",
    "    X_test_perc = selector.transform(X_test)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train_perc, Y_train)\n",
    "    return clf.predict(X_test_perc), Y_test\n",
    "\n",
    "good = 0\n",
    "bad = 0\n",
    "test_size = 100\n",
    "tic = time.perf_counter()\n",
    "for i in range(0, test_size):\n",
    "    p, t = test_p()\n",
    "    for j in range(0, len(p)):\n",
    "        if p[j] == t[j]:\n",
    "            good=good+1\n",
    "            continue\n",
    "        bad = bad+1\n",
    "toc = time.perf_counter()\n",
    "print('sukces: '+ str(good/(good+bad)))\n",
    "print(' time: '+ str(toc-tic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnią metodą, którą dzisiaj poznamy jest rekursywna eliminacja cech (RFE, ang. recursive feature elimination). Polega na tym, że estymator początkowo uczony jest na całym zbiorze danych i tworzony jest ranking cech w oparciu o to, jak bardzo są ważne podczas estymacji. Cechy najmniej istotne są usuwane i cały proces jest powtarzany. Usuwanie cech trwa tak długo, aż uzyskamy taką liczbę, jak sprecyzowana.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sukces: 0.95\n",
      " time: 38.64269279999917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "liczba_cech = 5\n",
    "step = 100\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=liczba_cech, step=step) #step - jeżeli >=1, to jest to liczba cech do \n",
    "                                                                    #usunięcia w danej iteracji, jeżeli <0 - \n",
    "                                                                    #część cech do usunięcia\n",
    "X_train_RFE = selector.fit_transform(X_train, Y_train)\n",
    "X_test_RFE = selector.transform(X_test)\n",
    "\n",
    "def test_RFE():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "    #estimator = LinearRegression()\n",
    "    #selector = RFE(estimator, n_features_to_select=5, step=10)\n",
    "    X_train_RFE = selector.fit_transform(X_train, Y_train)\n",
    "    X_test_RFE = selector.transform(X_test)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train_RFE, Y_train)\n",
    "    return clf.predict(X_test_RFE), Y_test\n",
    "\n",
    "good = 0\n",
    "bad = 0\n",
    "test_size = 50\n",
    "tic = time.perf_counter()\n",
    "for i in range(0, test_size):\n",
    "    p, t = test_RFE()\n",
    "    for j in range(0, len(p)):\n",
    "        if p[j] == t[j]:\n",
    "            good=good+1\n",
    "            continue\n",
    "        bad = bad+1\n",
    "toc = time.perf_counter()\n",
    "print('sukces: '+ str(good/(good+bad)))\n",
    "print(' time: '+ str(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powtórz proces uczenia i predykcji na cechach uzyskanych metodą RFE. Jakie wartości metryk wyszły tym razem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za tydzień omówimy jeszcze PCA i ICA, które też mogą być wykorzystywane do redukcji wymiarowości. Metod jest oczywiście więcej, ale nie zdążymy przerobić wszystkich. Dla zainteresowanych: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0cf854484826becf69b9363a35f769a3f32573db803431254cc95fc20fb81b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
