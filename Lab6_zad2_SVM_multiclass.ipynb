{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym zadaniu nadal będziemy pracować na danych dotyczących rodzajów fonacji. Tym razem zajmiemy się problem klasyfikacji wieloklasowej.\n",
    "\n",
    "W macierzy zawierającej cechy ponownie mamy 13 MFCC i ich I i II pochodną. Sygnałów jest 909 i przynależą do 5 klas:\n",
    "\n",
    "0. neutral - z nastawieniem miękkim\n",
    "1. pressed - z nastawieniem twardym, typ I\n",
    "2. pressedta - z nastawieniem twardym, typ II (wg autorów bazy \"while pressed vocalization was achieved by raising the larynx, pressedta was an attepmt to raise the subglottal pressure directly, without raising the larynx\")\n",
    "3. breathy - z nastawieniem chuchającym\n",
    "4. flow - \"phonation type produced with the largest peak-to-peak flow amplitude, where the minimum still reaches zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve, accuracy_score, f1_score, make_scorer, confusion_matrix, log_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 4 0 3 0 1 3 3 1 4 0 2 3 2 3 2 4 3 0 2 4 0 3 2 2 0 4 2 2 0 0 2 1 3 3 0\n",
      " 3 0 1 0 3 1 4 4 0 3 0 1 3 1 2 3 3 0 0 2 4 2 2 3 0 2 3 2 3 1 4 1 2 3 1 4 1\n",
      " 0 2 3 0 4 3 4 1 1 4 0 1 2 4 2 3 4 3 2 0 1 0 3 2 4 3 2 3 0 0 3 0 2 0 4 0 0\n",
      " 3 2 4 3 0 3 2 3 0 0 1 4 4 3 0 0 0 4 3 0 4 3 3 2 4 4 3 1 1 0 1 2 1 0 0 1 1\n",
      " 1 0 4 1 2 3 2 0 1 3 0 1 2 0 1 0 4 3 0 0 2 4 0 2 4 0 2 3 1 0 3 4 3 0 0 3 2\n",
      " 0 3 4 1 1 4 3 3 3 0 3 2 0 2 3 1 0 3 1 2 3 0 0 2 1 1 0 0 0 3 3 3 1 3 0 2 3\n",
      " 1 3 1 2 4 3 3 4 1 4 3 4 2 1 2 2 4 2 3 3 0 2 1 2 3 3 3 3 0 3 0 3 3 2 4 3 0\n",
      " 0 0 0 4 2 2 2 2 0 0 0 3 2 3 3 3 4 0 4 4 3 1 0 4 1 0 4 1 1 4 3 2 3 2 4 4 1\n",
      " 1 3 3 3 4 3 3 3 4 3 2 0 3 3 3 3 1 2 2 4 2 3 3 3 3 3 4 2 3 2 3 3 3 1 4 1 0\n",
      " 0 1 0 4 2 4 1 3 0 4 1 0 2 2 0 1 3 3 3 4 3 3 0 4 1 2 0 0 0 2 3 4 3 0 4 1 0\n",
      " 0 0 0 2 0 4 2 1 1 0 1 4 3 0 2 3 1 1 2 1 3 3 2 0 3 4 1 3 0 0 4 0 3 0 0 3 2\n",
      " 1 3 0 3 4 1 0 4 1 1 0 0 3 4 0 4 4 3 0 4 3 3 4 3 4 0 0 4 1 0 3 2 3 2 3 3 4\n",
      " 4 2 2 1 3 0 1 0 0 3 0 3 3 2 1 4 2 4 0 2 0 0 3 1 0 3 2 2 1 2 0 4 3 0 4 0 0\n",
      " 3 0 0 1 3 4 3 1 0 2 1 1 0 2 3 4 2 4 0 0 0 0 1 1 4 4 0 0 3 3 1 0 3 3 3 1 3\n",
      " 3 2 2 0 3 2 3 3 3 2 3 4 3 4 3 2 1 3 1 2 4 0 3 3 4 1 1 3 0 3 4 1 3 4 1 0 3\n",
      " 0 1 1 0 3 0 2 4 2 1 4 2 4 2 1 1 1 2 4 3 3 0 0 1 3 0 2 3 3 1 1 0 3 3 1 0 1\n",
      " 3 3 1 4 4 2 3 0 4 2 0 3 0 4 0 3 3 0 4 2 0 0 3 2 0 2 3 0 3 3 0 3 4 3 0 0 1\n",
      " 1 0 4 1 1 4 1 3 4 4 0 4 3 1 4 1 0 3 3 0 2 4 0 3 3 4 0 2 2 2 2 3 4 1 4 4 2\n",
      " 4 0 0 3 3 3 3 3 2 3 4 3 4 2 0 2 4 0 2 0 3 0 3 3 1 3 3 0 3 3 3 0 2 1 3 0 0\n",
      " 1 1 2 0 1 4 2 3 3 0 4 3 2 2 0 4 2 0 0 0 4 0 1 0 3 0 2 2 3 0 2 3 0 0 0 2 0\n",
      " 4 0 0 3 3 0 4 0 0 1 3 1 2 1 3 3 4 4 1 4 0 0 2 0 1 1 0 4 1 0 4 0 3 1 1 4 3\n",
      " 1 0 3 3 3 0 1 3 4 0 4 3 2 3 1 0 3 3 3 0 3 2 1 2 0 1 2 0 3 0 0 3 0 4 0 3 4\n",
      " 2 1 0 2 0 4 2 0 3 2 4 0 0 4 0 4 0 2 0 3 3 4 4 0 4 2 1 0 2 1 0 1 0 3 2 4 3\n",
      " 2 3 3 0 1 1 1 1 3 0 1 3 4 1 2 0 3 3 2 0 3 3 1 4 1 2 2 3 0 4 0 3 3 2 4 0 2\n",
      " 3 2 4 0 1 0 1 0 3 3 2 0 4 4 4 3 3 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#wczytywanie danych\n",
    "X = np.load('padded_feats.npy') #macierz cech - jednej wiersz = jeden obiekt\n",
    "y = np.load('labels.npy') #labele\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42) #podział na zbiory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train) #standaryzacja\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC(C=1.0, random_state=42)\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikację wykonuje się tak samo bez względu na to, ile klas jest w zbiorze. Należy użyć metody fit na zbiorze uczącym, a następnie predict na zbiorze testowym. Różnica jest w obliczaniu metryk - większość z nich wymaga określenia, która klasa jest pozytywna, a która negatywna. Gdy mamy więcej niż 2 klasy, metryki wylicza się uśredniając wyniki uzyskane dla każdej z klas (zazwyczaj przy założeniu, że jest aktualnie rozpatrywana klasa jest pozytywna, a pozostałe negatywne). Trzeba określić, w jaki sposób będzie wyliczana średnia. Można wybrać trzy rodzaje:\n",
    "\n",
    "- weighted - średnia ważona, najlepsza, gdy mamy nierównoliczne klasy\n",
    "- macro - średnia arytmetyczna, a nie ważona\n",
    "- micro  - wynik wyznaczony globalnie poprzez zliczenie wszystkich TP, FP i FN (od razu dla całych danych, a nie dla każdej klasy z osobna).\n",
    "\n",
    "Policzmy, ile mamy obiektów w każdej z klas w zbiorze testowym, żeby wybrać sposób uśredniania przy liczeniu metryk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter_ytest = Counter(y_test)\n",
    "plt.bar(counter_ytest.keys(), counter_ytest.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, klasy nie są równolicze, np. klasy 3 jest prawie 2x więcej niż klasy 1. Dlatego użyjemy średniej ważonej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  0.47368421052631576\n",
      "test F1 =  0.36968016633760686\n",
      "[[44  0  0 14  0]\n",
      " [ 2  0  7 26  0]\n",
      " [ 2  0  9 26  0]\n",
      " [ 7  0  0 55  0]\n",
      " [31  0  0  5  0]]\n"
     ]
    }
   ],
   "source": [
    "SVM_test_preds = SVM.predict(X_test)\n",
    "print('test accuracy = ', accuracy_score(y_test, SVM_test_preds))\n",
    "print('test F1 = ', f1_score(y_test, SVM_test_preds, average='weighted'))\n",
    "print(confusion_matrix(y_test, SVM_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macierz pomyłek jest dużo bardziej rozbudowana, niż w przypadku klasyfikacji binarnej. Da się z niej odczytać nie tylko, które obiekty zostały zaklasyfikowane poprawnie (wartości na przekątnej), ale też spradzić, do której konkretnie klasy zostały przyporządkowane te, które zaklasyfikowano nieprawidłowo.\n",
    "\n",
    "Dokładność i F1 uzyskane przy domyślnej wartości C=1 nie są zbyt dobre i model nie nauczył się prawidłowo klasyfikować obiektów. Widać to też na podstawie macierzy pomyłek - żaden obiekt z klasy 1 i 4 nie został zaklasyfikowany prawidłowo, a najwięcej zaklasyfikowano do klasy 3.\n",
    "\n",
    "To była klasyfikacja na danych nieustandaryzowanych. Przeprowadź teraz klasyfikację używając X_train_scaled i X_test_scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  0.8070175438596491\n",
      "test F1 =  0.8054811520887298\n",
      "[[45  1  0  7  5]\n",
      " [ 3 25  6  0  1]\n",
      " [ 2  8 26  0  1]\n",
      " [ 2  0  0 60  0]\n",
      " [ 5  3  0  0 28]]\n"
     ]
    }
   ],
   "source": [
    "SVM_scaled = SVC(C=1.0, random_state=42)\n",
    "SVM_scaled.fit(X_train_scaled, y_train)\n",
    "SVM_test_preds = SVM_scaled.predict(X_test_scaled)\n",
    "print('test accuracy = ', accuracy_score(y_test, SVM_test_preds))\n",
    "print('test F1 = ', f1_score(y_test, SVM_test_preds, average='weighted'))\n",
    "print(confusion_matrix(y_test, SVM_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby spróbować jeszcze bardziej poprawić wyniki, trzeba zoptymalizować model. Robi się to tak samo, jak w zadaniu poprzednim z jedną różnicą - w przypadku modeli regresyjnych i klasyfikatorów binarnych funkcją celu może być ROC AUC, natomiast w przypadku większej liczby klas trzeba wybrać inną metrykę. Najczęściej jest to czułość (accuracy) lub F1. Zacznijmy od F1, które teoretycznie jest lepszą metryką, bo zawiera w sobie precyzję i czułość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'f1_macro': make_scorer(f1_score, average='weighted')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniuj pozostałe potrzebne funkcje i zmienne: funkcję objective, model, space i trials. Zoptymalizyj model i wylicz dokładność, F1 i wyznacz macierz pomyłek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 22:29:23,562]\u001b[0m A new study created in memory with name: no-name-4e34f639-8f2a-450d-9c5d-ed3c1b58e9ab\u001b[0m\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_11020\\965075820.py:2: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  space = {\"C\": trial.suggest_uniform(\"C\", 0, 1),\n",
      "\u001b[32m[I 2022-12-19 22:33:26,477]\u001b[0m Trial 0 finished with value: 0.7148108734517468 and parameters: {'C': 0.38560771739462496, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.7148108734517468.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def get_space(trial): \n",
    "    space = {\"C\": trial.suggest_uniform(\"C\", 0, 1), \n",
    "           \"kernel\": trial.suggest_categorical(\"kernel\", ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "            'degree': trial.suggest_int('degree', 1,3)}\n",
    "    return space\n",
    "\n",
    "def objective(trial, model, get_space, X, y):\n",
    "    model_space = get_space(trial)\n",
    "\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(mdl, X, y, scoring=scoring, cv=StratifiedKFold(n_splits=5), return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_f1_macro'])\n",
    "model = SVC\n",
    "trials = 10\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda x: objective(x, model, get_space, X_train_scaled, y_train), n_trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  0.7631578947368421\n",
      "test F1 =  0.7587828977983683\n",
      "[[47  1  0  8  2]\n",
      " [ 3 23  7  1  1]\n",
      " [ 3 11 21  2  0]\n",
      " [ 2  0  0 60  0]\n",
      " [ 9  4  0  0 23]]\n"
     ]
    }
   ],
   "source": [
    "SVM_scaled = SVC(**study.best_params)\n",
    "SVM_scaled.fit(X_train_scaled, y_train)\n",
    "SVM_test_preds = SVM_scaled.predict(X_test_scaled)\n",
    "print('test accuracy = ', accuracy_score(y_test, SVM_test_preds))\n",
    "print('test F1 = ', f1_score(y_test, SVM_test_preds, average='weighted'))\n",
    "print(confusion_matrix(y_test, SVM_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powtórz proces optymalizacji dla funkcji celu zdefiniowanej przez dokładność. Która dała lepsze wyniki? Jak bardzo udało się poprawić wyniki w porównaniu do nieoptymalizowanego modelu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy_macro': make_scorer(accuracy_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 22:34:08,943]\u001b[0m A new study created in memory with name: no-name-7e56e1b9-b867-4157-b964-380844a614e3\u001b[0m\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_11020\\2373404125.py:2: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  space = {\"C\": trial.suggest_uniform(\"C\", 0, 1),\n",
      "\u001b[32m[I 2022-12-19 22:36:52,396]\u001b[0m Trial 0 finished with value: 0.7944289394589953 and parameters: {'C': 0.8898434776093302, 'kernel': 'sigmoid', 'degree': 3}. Best is trial 0 with value: 0.7944289394589953.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def get_space(trial): \n",
    "    space = {\"C\": trial.suggest_uniform(\"C\", 0, 1), \n",
    "           \"kernel\": trial.suggest_categorical(\"kernel\", ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "            'degree': trial.suggest_int('degree', 1,3)}\n",
    "    return space\n",
    "\n",
    "def objective(trial, model, get_space, X, y):\n",
    "    model_space = get_space(trial)\n",
    "\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(mdl, X, y, scoring=scoring, cv=StratifiedKFold(n_splits=5), return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_accuracy_macro'])\n",
    "model = SVC\n",
    "trials = 10\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda x: objective(x, model, get_space, X_train_scaled, y_train), n_trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  0.8114035087719298\n",
      "test F1 =  0.8104435064450367\n",
      "[[47  1  0  8  2]\n",
      " [ 3 25  5  0  2]\n",
      " [ 0 10 25  1  1]\n",
      " [ 2  0  0 60  0]\n",
      " [ 4  4  0  0 28]]\n"
     ]
    }
   ],
   "source": [
    "SVM_scaled = SVC(**study.best_params)\n",
    "SVM_scaled.fit(X_train_scaled, y_train)\n",
    "SVM_test_preds = SVM_scaled.predict(X_test_scaled)\n",
    "print('test accuracy = ', accuracy_score(y_test, SVM_test_preds))\n",
    "print('test F1 = ', f1_score(y_test, SVM_test_preds, average='weighted'))\n",
    "print(confusion_matrix(y_test, SVM_test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0cf854484826becf69b9363a35f769a3f32573db803431254cc95fc20fb81b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
