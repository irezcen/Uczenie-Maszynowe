{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dzisiejszych zajęciach będziemy zajmować się algorytmami drzewiastymi. Poznamy dwa algorytmy z biblioteki scikit-learn: random forest (lasy losowe) oraz extra trees.   \n",
    "\n",
    "Oprócz tego zrobimy krótkie wprowadzenie do pakietu LightGBM wykorzystującego metodę wzmocnienia gradientowego.\n",
    "\n",
    "Dane, na których będziemy pracować dotyczą tzw. klasyfikacji zdarzeń akustycznych (ang. acoustic event classification). Są to różnego rodzaju dźwięki, które można spotkać w mieście - głosy ludzi, zwierząt, odgłosy wydawane przez urządzenia techniczne, samochody itp. Jest to dość trudny problem klasyfikacyjny, ponieważ próbujemy nauczyć model rozpoznawania wielu klas naraz.\n",
    "\n",
    "Źrodło danych: https://www.kaggle.com/chrisfilo/urbansound8k?fbclid=IwAR2AwTcNOEFFJGq3Me5C2o6lLJ_jMTzo5PUdB2EWStjTaBq1z1CVCCQG0Uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve, accuracy_score, recall_score, f1_score, make_scorer, confusion_matrix, log_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_validate, GroupKFold\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak ostatnio, będziemy pracować na plikach z wyekstrahowanymi wcześniej cechami, żeby nie tracić czasu na ich wyliczanie. Będziemy wykorzystywać dwa rodzaje cech: poznane już wcześniej MFCC oraz bardzo podobne cechy, których jeszcze nie omawialiśmy - GFCC (ang. gammatone frequency cepstral coefficients).\n",
    "\n",
    "GFCC to kolejny rodzaj cech bazujący na modelu psychoakustycznym, który ma za zadanie opisać w sposób matematyczny działanie ludzkiego układu słuchowego. Od MFCC różni się przede wszystkich kształtem filtrów stosowanych do przetwarzania sygnałów - w przypadku MFCC są to filtry trójkątne, natomiast GFCC wyliczane są przy użyciu filtrów gammatone. Filtry gammatone mają nieco bardziej naturalny, fizjologiczny kształt - wierzchołek jest zaokrąglony, a nie ostry jak w filtrach trójkątnych:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://www.researchgate.net/profile/Peter-Balazs/publication/309663739/figure/fig2/AS:614042511085584@1523410551779/A-popular-auditory-filter-model-the-gammatone-filter-bank-The-magnitude-responses-in.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikację przeprowadzimy na początek używając tylko MFCC i lasów losowych. Wczytujemy 3 pliki:\n",
    "- mfcc_feats.npy - macierz z 13 MFCC\n",
    "- labels.npy - wektor z labelami (przyporządkowaniem do klas)\n",
    "- folds.npy - podział na foldy (podzbiory), który ma być wykorzystany podczas walidacji krzyżowej. \n",
    "\n",
    "Dotychczas walidację krzyżową robiliśmy dzieląc dane na podzbiory w sposób losowy - czasem podział jest istotny i powinien być przeprowadzony w określony sposób. Jest tak np. wtedy, gdy w bazie znajduje się więcej niż jeden sygnał zawierający dźwięki emitowane przez to samo urządzenie lub tę samą osobę. Wtedy należy zagwarantować, żeby  wszystkie sygnały związane z tym samym obiektem znalazły się w tym samym podzbiorze - gdyby tak nie było, to uzyskalibyśmy sztucznie zawyżone metryki i mielibyśmy złe pojęcie o jakości naszego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7334, 13, 345)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mfcc = np.load('lab7/mfcc_3D.npy')\n",
    "y_org = np.load('lab7/labels.npy')\n",
    "folds = np.load('lab7/folds.npy')\n",
    "#klasy\n",
    "# 0 = airconditioner 1 = carhorn 2 = childrenplaying 3 = dogbark 4 = drilling\n",
    "# 5 = engineidling 6 = gunshot 7 = jackhammer 8 = siren 9 = street_music\n",
    "\n",
    "X_mfcc.shape #mamy 7334 sygnałów o długości 345 ramek, z każdego wyekstrahowano 13 MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdybyśmy utworzyli z macierzy MFCC wektor, mielibyśmy każdy sygnał opisany 4486 cechami - algorytmy drzewiaste uczyłyby się na takich danych bardzo długo. Dlatego chcemy mieć dane o mniejszych wymiarach.\n",
    "\n",
    "Tym razem nie będziemy zmniejszać wymiarowości danych używając algorytmów, które poznaliśmy do tej pory. Zamiast tego wyliczymy parametry statystyczne charakteryzujące każdy kanał (każdy z 13 współczynników cepstralnych) na całej długości sygnału. Będą to bardzo podstawowe parametry:\n",
    "- wartość średnia, \n",
    "- odchylenie standardowe, \n",
    "- mediana, \n",
    "- I i III kwartyl, \n",
    "- rozrzut pomiędzy 10 i 90 percentylem, \n",
    "- kurtoza, \n",
    "- skośność, \n",
    "- wartość minimalna,\n",
    "- wartość maksymalna. \n",
    "\n",
    "Takie cechy są czasem stosowane w przemyśle, np. w analizie mowy, więc warto wiedzieć, że można ich używać i że potrafią dawać dobre rezultaty.\n",
    "\n",
    "Teraz każdy sygnał będzie opisany tylko 130 cechami, więc można prowadzić proces uczenia, walidacji i predykcji bez dalszej redukcji wymiarowości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.mean(X_mfcc, axis=2), \n",
    "               np.std(X_mfcc, axis=2), \n",
    "               np.median(X_mfcc, axis=2), \n",
    "               np.percentile(X_mfcc, 25, axis=2), \n",
    "               np.percentile(X_mfcc, 75, axis=2), \n",
    "               scipy.stats.iqr(X_mfcc, rng=(10, 90), axis=2),\n",
    "               scipy.stats.kurtosis(X_mfcc, axis=2),\n",
    "               scipy.stats.skew(X_mfcc, axis=2),\n",
    "               np.min(X_mfcc, axis=2),\n",
    "               np.max(X_mfcc, axis=2)\n",
    "              ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlmy liczebność poszczególnych klas, żeby zobaczyć, czy mają podobną liczebność - jeżeli różnica pomiędzy liczebnością klas będzie bardzo duża, to prawdopodobnie klasyfikator nie będzie w stanie nauczyć się ich poprawnie rozpoznawać bez dodatkowego preprocessingu, np. nad- lub podpróbkowania klas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 976,\n",
       "         3: 675,\n",
       "         0: 997,\n",
       "         9: 1000,\n",
       "         8: 897,\n",
       "         5: 961,\n",
       "         7: 804,\n",
       "         4: 805,\n",
       "         1: 203,\n",
       "         6: 16})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać najmniej liczba jest klasa 6 - należy do niej tylko 16 obiektów, czyli 0,2% wszystkich danych. Usuniemy wszystkie obiekty z tej klasy ze zbioru danych, ponieważ będą tylko utrudniać proces uczenia.\n",
    "\n",
    "Wykorzystamy podzbiór nr 10 jako zbiór testowy, a pozostałe 9 podzbiorów będzie tworzyło zbiór uczący. Walidacja krzyżowa, którą będziemy robić za chwilę, będzie w takim razie 9-krotna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7334,)\n"
     ]
    }
   ],
   "source": [
    "#usuwanie klasy 6 ze zbioru danych\n",
    "y_not_6 = y_org!=6\n",
    "print(folds.shape)\n",
    "\n",
    "X = X[y_not_6]\n",
    "folds = folds[y_not_6]\n",
    "y = y_org[y_not_6]\n",
    "\n",
    "#podział na zbiór uczący i testowy\n",
    "train_folds_mask = folds != 10\n",
    "test_fold_mask = folds == 10\n",
    "\n",
    "train_folds = folds[train_folds_mask]\n",
    "test_fold = folds[test_fold_mask]\n",
    "\n",
    "X_train = X[train_folds_mask]\n",
    "X_test = X[test_fold_mask]\n",
    "\n",
    "y_train = y[train_folds_mask]\n",
    "y_test = y[test_fold_mask]\n",
    "\n",
    "print(train_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnim krokiem przed uczeniem modelu będzie standaryzacja danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAS LOSOWY\n",
    "\n",
    "Mamy już przygotowane dane, więc możemy zdefiniować, która metryka posłuży do walidacji modelu w czasie walidacji krzyżowej oraz przejść do uczenia modelu. Zaczniemy od lasu losowego, czyli klasyfikatora Random Forest.\n",
    "\n",
    "Do wyjaśnienia zasady działania lasów losowych potrzebna jest znajomość drzew decyzyjnych. Drzewa decyzyjne to hierachiczny algorytm, który tworzy proste reguły dotyczące wartości cech, które pozwalają dokonać podziału danych na klasy (lub przewidywania wartości w przypadku regresji). Początek drzewa, czyli miejsce, w którym dane będą po raz pierwszy podzielone nazywany jest korzeniem. Każde kolejne miejsce, znajdujące się co najmniej poziom niżej od korzenia, to węzeł. Na końcu drzewa znajdują się liście - w liściach nie następują już dalsze podziały, ponieważ albo znajdują się w nich obiekty z tylko jednej klasy, albo został osiągnięty narzucony warunek zatrzymania algorytmu. Węzły połączone są ze sobą oraz z liśćmi krawędziami. \n",
    "\n",
    "W węzłach zapisane są warunki dalszego podziału, dotyczące pojedynczych cech lub ich kombinacji liniowych. Predykcja polega na przejściu przez wszystkie poziomy drzewa, sprawdzając, czy spełnione są zapisane w kolejnych węzłach warunki. Na końcu docieramy do liścia, w którym zawarta jest informacja, do której klasy przynależy obiekt.\n",
    "\n",
    "Poniżej przykład drzewa decyzyjnego służącego do określenia, czy u pacjenta występuje podwyższone ryzyko zawału mięśnia sercowego:\n",
    "\n",
    "![caption](https://pranav-ap.netlify.app/media/machine%20learning/decision%20trees/decision-tree.png)\n",
    "\n",
    "Trochę bardziej wyczerpujący opis można przeczytac np. tu: http://aiway.pl/drzewa-decyzyjne/\n",
    "\n",
    "Las losowy to zbiór drzew klasyfikacyjnych. Każde drzewo uczone jest na innym, losowym podzbiorze danych - w ten sposób każde drzewo może uczyć się na innym zestawie obiektów. Dodatkowo, w każdym węźle drzewa podział dokonywany jest w oparciu o losowo wybrane cechy (czyli nie bierzemy pod uwagę wszystkich cech opisujących obiekt, a jedynie część z nich). Ostateczna przynależność do klas określana jest na drodze głosowania - każde drzewo zwraca decyzję, a cały las wybiera tę klasę, która pojawiła się najwięcej razy w predykcjach pojedynczych drzew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'f1_macro': make_scorer(f1_score, average='macro')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli mamy z góry określony podział na podzbiory, którego mamy użyć podczas walidacji krzyżowej, funkcji cross_validate należy użyć w taki sposób:\n",
    "- najpierw podajemy model, który będzie uczony,\n",
    "- następnie macierz cech uczących oraz wektor labeli zbioru uczącego,\n",
    "- określamy, jaka metryka będzie wykorzystywana do walidacji, czyli scoring,\n",
    "- definiujemy parametr groups - jest to podział obiektów na podzbiory określony w zmiennej train_folds (dla każdego obiektu podany jest numer podzbioru, w którym ma się znaleźć),\n",
    "- do parametry cv przypisujemy GroupKFold(n_splits=len(np.unique(train_folds))) - to jest to miejsce, w którym algorytm walidacji krzyżowej sprawdza, ile podzbiorów ma być utworzonych i dostaje informację, że ma ten podział zrobić na podstawie numerów podzbiorów zawartych w train_folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "scores = cross_validate(model, X_train, y_train, scoring=scoring, groups=train_folds, cv=GroupKFold(n_splits=len(np.unique(train_folds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlmy sobie, jakie wartości F1 uzyskaliśmy dla każdego podzbioru podczas walidacji krzyżowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([13.96679282, 10.96430492, 11.15365911,  9.43510866,  9.02480412,\n",
       "         9.6541481 ,  9.86483312, 10.10695052, 13.18539429]),\n",
       " 'score_time': array([0.05573964, 0.09884977, 0.06856418, 0.05012226, 0.04794526,\n",
       "        0.06979537, 0.06677055, 0.12436891, 0.07514787]),\n",
       " 'test_f1_macro': array([0.6351108 , 0.46780824, 0.59506957, 0.50502088, 0.56636187,\n",
       "        0.59618002, 0.57521537, 0.57631282, 0.54417924])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, wyniki nie są szczególnie dobre - dla 8 z 9 podzbiorów uzyskaliśmy F1 < 0.6. Jeżeli teraz przeprowadzimy walidację prostą (czyli uczenie na całym zbiorze uczącym i predykcje na testowym), to raczej też nie uzyskamy zadowalających wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  7  0  1 33  0  0  9]\n",
      " [ 0  0 11  0  0  3  0  1  1]\n",
      " [ 1  0 73  6  0  2  0  3 13]\n",
      " [ 0  0 12 42  0  0  0  4 10]\n",
      " [ 0  0  4  0 47 12  5 12  4]\n",
      " [ 8  0  0  0  0 65  6  0 10]\n",
      " [ 0  0  0  0 26  0 47  0  0]\n",
      " [ 0  0 37  1  3  0  1 35  0]\n",
      " [ 0  0 14  0  2  0  1  2 81]]\n",
      "0.624113475177305\n"
     ]
    }
   ],
   "source": [
    "#Przeprowadź trening klasyfikatora RandomForest z random_state=42 i domyślnymi wartościami pozostałych\n",
    "#hiperparamterów oraz predykcję na zbiorze testowy. \n",
    "#Wyświetl macierz pomyłek, F1 i dokładność (accuracy)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "test_preds = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, test_preds))\n",
    "print(accuracy_score(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy również wyświetlić, które cechy miały największy wpływ na wynik klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01347559, 0.01289423, 0.0089694 , 0.0161301 , 0.00939055,\n",
       "       0.00598816, 0.00843287, 0.00871002, 0.01048525, 0.00659015,\n",
       "       0.00818963, 0.00719654, 0.00606685, 0.01578409, 0.01063738,\n",
       "       0.00917164, 0.00927458, 0.01003863, 0.00670233, 0.00834102,\n",
       "       0.00693825, 0.00565679, 0.00898747, 0.01707306, 0.00743833,\n",
       "       0.00694824, 0.01290899, 0.01173283, 0.00904746, 0.01418193,\n",
       "       0.00904204, 0.00573058, 0.00862992, 0.00790943, 0.00958022,\n",
       "       0.00760183, 0.00683907, 0.00605683, 0.00523785, 0.01172233,\n",
       "       0.01124313, 0.00911116, 0.01507182, 0.01249784, 0.00612842,\n",
       "       0.00799496, 0.00721569, 0.00766232, 0.0071994 , 0.0083708 ,\n",
       "       0.00682377, 0.00518819, 0.01275915, 0.01298717, 0.01020599,\n",
       "       0.01522327, 0.00799157, 0.00572296, 0.00856745, 0.01128347,\n",
       "       0.01250434, 0.00661601, 0.00850692, 0.00784823, 0.00684716,\n",
       "       0.01481661, 0.01488154, 0.011767  , 0.0096766 , 0.0087968 ,\n",
       "       0.00529765, 0.00913274, 0.00938902, 0.00433273, 0.00900196,\n",
       "       0.00801104, 0.00868641, 0.00575247, 0.00354516, 0.00291039,\n",
       "       0.00276312, 0.00251073, 0.00261672, 0.0022612 , 0.00265121,\n",
       "       0.00257297, 0.00317993, 0.00351083, 0.00423936, 0.00478539,\n",
       "       0.00300931, 0.00538002, 0.00416543, 0.00404894, 0.00297667,\n",
       "       0.00385127, 0.00240095, 0.0027977 , 0.00265927, 0.00264392,\n",
       "       0.00231568, 0.00210556, 0.00197176, 0.00220464, 0.00667111,\n",
       "       0.00752833, 0.0110788 , 0.01575176, 0.01061056, 0.00571589,\n",
       "       0.006154  , 0.00758194, 0.00533897, 0.00607441, 0.00575151,\n",
       "       0.00544303, 0.0047868 , 0.00905372, 0.01326472, 0.00701084,\n",
       "       0.01144387, 0.00745496, 0.00523213, 0.00582432, 0.00794228,\n",
       "       0.00818268, 0.00645124, 0.00752803, 0.00490782, 0.00429194])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy znaleźć indeksy cech, które są najbardziej i najmniej istotne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 102)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.feature_importances_), np.argmin(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Największy wpływ na wynik klasyfikacji miała cecha nr 23, a najmniejszy - 102. Patrząc na sposób tworzenia macierzy X możemy wywnioskować, że najistotniejsze jest odchylenie standardowe 10 kanału MFCC, zaś najmniej istotna - skośność 11 kanału.\n",
    "\n",
    "Robiąc takie analizy moglibyśmy usunąć te najmniej istotne cechy i w ten sposób przeprowadzić redukcję wymiarowości. Nie będziemy tego teraz robić, ponieważ chcemy porównać wyniki uzyskiwane na różnych zbiorach cech oraz przy użyciu różnych klasyfikatorów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przypuszczenia oparte o wyniki dla podzbiorów walidacyjnych potwiedziły się i wyniki uzyskane na zbiorze testowym nie są zbyt dobre, chociaż też nie można powiedzieć, że są tragiczne - dokładność 0.62 dla modelu z domyślnymi wartościami hiperparametrów i przy 9 klasach to całkiem dobry wyniki. Widać natomiast, że np. żaden obiekt z klasy 2 nie zostal zaklasyfikowany prawidłowo, więc warto spróbować uzyskać lepszy model.\n",
    "\n",
    "Możemy wypróbować kolejne cechy, czyli GFCC. Podziału na zbiory i labeli nie musimy wczytywać na nowo, bo pozostają bez zmian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7318\n",
      "7318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7334, 13, 345)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y)) #długość wektora y po usunięciu obiektów z klasy 6\n",
    "X_gfcc = np.load('lab7/gfcc_3D.npy')\n",
    "print(len(y)) #długość wektora y przed usunięciem obiektów z klasy 6\n",
    "X_gfcc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejne etapy są takie same - należy wyliczyć statystyki, usunąć klasę 6 z macierzy X i podzielić dane na zbiór uczący i testowy tak, by w testowym był tylko 10 podzbiór, a w uczącym pozostałe 9 podzbiorów.\n",
    "\n",
    "Zrób to poniżej, nie nadpisując starego kodu - będziemy porównywać uzyskane wyniki, więc dobrze będzie mieć dostęp do tego, co wyszło przed chwilą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wylicz statystyki\n",
    "X_gfcc_params = np.hstack((np.mean(X_gfcc, axis=2), \n",
    "               np.std(X_gfcc, axis=2), \n",
    "               np.median(X_gfcc, axis=2), \n",
    "               np.percentile(X_gfcc, 25, axis=2), \n",
    "               np.percentile(X_gfcc, 75, axis=2), \n",
    "               scipy.stats.iqr(X_gfcc, rng=(10, 90), axis=2),\n",
    "               scipy.stats.kurtosis(X_gfcc, axis=2),\n",
    "               scipy.stats.skew(X_gfcc, axis=2),\n",
    "               np.min(X_gfcc, axis=2),\n",
    "               np.max(X_gfcc, axis=2)\n",
    "              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7318,)\n"
     ]
    }
   ],
   "source": [
    "#usuń klasę 6 i podziel dane na zbiory\n",
    "#usuwanie klasy 6 ze zbioru danych\n",
    "print(folds.shape)\n",
    "\n",
    "X_gfcc_params = X_gfcc_params[y_not_6]\n",
    "\n",
    "X_train_gfcc = X_gfcc_params[train_folds_mask]\n",
    "X_test_gfcc = X_gfcc_params[test_fold_mask]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_gfcc = scaler.fit_transform(X_train_gfcc)\n",
    "X_test_gfcc = scaler.transform(X_test_gfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#przeprowadź walidację krzyżową klasyfikatora RandomForest (zastosuj taki sam random_state jak wcześniej)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "scores_gfcc = cross_validate(model, X_train_gfcc, y_train, scoring=scoring, groups=train_folds, cv=GroupKFold(n_splits=len(np.unique(train_folds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f49dbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([18.66571116, 13.86148214, 11.8635776 , 11.42606711, 11.59590411,\n",
       "        11.54210591, 13.43760777, 13.63634539, 13.73947668]),\n",
       " 'score_time': array([0.06210637, 0.05098963, 0.03612876, 0.04559302, 0.0818572 ,\n",
       "        0.04013205, 0.03224707, 0.05351329, 0.09697938]),\n",
       " 'test_f1_macro': array([0.47118627, 0.38431533, 0.48526217, 0.41145696, 0.41658662,\n",
       "        0.4106849 , 0.42931284, 0.47413933, 0.44017885])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_gfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  0 13  0  3 11  3  1  0]\n",
      " [ 1  0  4  1  5  0  1  0  4]\n",
      " [11  0 62  2  1  5  5  0 12]\n",
      " [ 2  0  8 44  0  1  0  1 12]\n",
      " [16  0  6  5 33  5  5  4 10]\n",
      " [19  0  5  0  0 43 11  2  9]\n",
      " [ 0  0  2  0  2  6 48  0 15]\n",
      " [ 9  0 22  1  3  2  0 31  9]\n",
      " [ 4  0 23  1 11  2  6  7 46]]\n",
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Przeprowadź trening klasyfikatora RandomForest z random_state=42 i domyślnymi wartościami pozostałych\n",
    "#hiperparamterów oraz predykcję na zbiorze testowy. \n",
    "#Wyświetl macierz pomyłek, F1 i dokładność (accuracy)\n",
    "clf_gfcc = RandomForestClassifier(random_state=42)\n",
    "clf_gfcc.fit(X_train_gfcc, y_train)\n",
    "gfcc_preds = clf_gfcc.predict(X_test_gfcc)\n",
    "print(confusion_matrix(y_test, gfcc_preds))\n",
    "print(accuracy_score(y_test, gfcc_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tym razem wyniki są znacząco gorsze niż te uzyskane na MFCC. \n",
    "\n",
    "Spróbujemy zwiększyć dokładność predykcji ucząc model na obu typach cech naraz. Takie postępowanie, czyli wykorzystywanie zbioru różnych cech, które pojedynczo nie dają dobrych rezultatów, często pozwala znacząco poprawić jakość modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7334, 26, 345)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_both = np.hstack((X_mfcc, X_gfcc))\n",
    "\n",
    "X_both.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ponownie wylicz statystyki\n",
    "X_both_params = np.hstack((np.mean(X_both, axis=2), \n",
    "               np.std(X_both, axis=2), \n",
    "               np.median(X_both, axis=2), \n",
    "               np.percentile(X_both, 25, axis=2), \n",
    "               np.percentile(X_both, 75, axis=2), \n",
    "               scipy.stats.iqr(X_both, rng=(10, 90), axis=2),\n",
    "               scipy.stats.kurtosis(X_both, axis=2),\n",
    "               scipy.stats.skew(X_both, axis=2),\n",
    "               np.min(X_both, axis=2),\n",
    "               np.max(X_both, axis=2)\n",
    "              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7334, 260)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_both_params.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cech opisujących pojedynczy obiekt mamy teraz co prawda aż 260, ale nadal nie jest to na tyle duża liczba, żeby proces uczenia trwał bardzo długo lub było duże ryzyko przeuczenia modelu, więc możemy nie robić redukcji wymiarowości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuń klasę 6, podziel dane na zbiory i przeprowadź walidację krzyżową, trening i predykcję\n",
    "X_both_params = X_both_params[y_not_6]\n",
    "\n",
    "X_train_both = X_both_params[train_folds_mask]\n",
    "X_test_both = X_both_params[test_fold_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_both = scaler.fit_transform(X_train_both)\n",
    "X_test_both = scaler.transform(X_test_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "647fc826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0 11  0  2 31  1  0  5]\n",
      " [ 0  1 10  0  0  2  0  0  3]\n",
      " [ 0  0 80  2  0  1  0  3 12]\n",
      " [ 1  0  9 50  0  0  0  1  7]\n",
      " [ 3  0 10  2 39 20  1  4  5]\n",
      " [10  0  2  0  4 59  3  1 10]\n",
      " [ 0  0  0  0 10  0 62  0  1]\n",
      " [ 0  1 35  0  1  0  0 39  1]\n",
      " [ 1  1 12  1  2  0  0  1 82]]\n",
      "0.6553191489361702\n"
     ]
    }
   ],
   "source": [
    "clf_both = RandomForestClassifier(random_state=42)\n",
    "clf_both.fit(X_train_both, y_train)\n",
    "both_preds = clf_both.predict(X_test_both)\n",
    "print(confusion_matrix(y_test, both_preds))\n",
    "print(accuracy_score(y_test,both_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki, które uzyskaliśmy na MFCC i GFCC równocześnie są już bardziej obiecujące - nawet na nieoptymalizowanym modelu udało uzyskać się dokładność i F1 przekraczające 0.65.\n",
    "\n",
    "Skoro już wiemy, że na takich danych uzyskujemy najlepsze wyniki, możemy przejść do optymalizacji modelu. Będziemy optymalizować 3 hiperparamtry:\n",
    "- n_estimators - liczba drzew klasyfikacyjnych, które będą tworzyły las,\n",
    "- max_depth - maksymalna głębokość (liczba poziomów) drzewa,\n",
    "- min_samples_split - minimalna liczba obiektów, które muszą znajdować się w węźle, by można go było poddać kolejnemu podziałowi.\n",
    "\n",
    "Dodamy też parametr n_jobs, który określna liczbę rdzeni, które zostaną wykorzytane do treningu. -1 oznacza wszystkie dostępne - taki wybór przyspieszy optymalizację, ale spowolni działanie innych procesów.\n",
    "\n",
    "Liczbę triali ustawimy na 60 - jest to wartość dobrana eksperymentalnie pozwalająca na uzyskanie w miarę dobrych wyników. W domu lub pod koniec zajęć możesz spróbować zwiększyć ją np. do 100 lub 150 i zobaczyć, czy wyniki uda się poprawić, czy optimum będzie jednak osiągnięte wcześniej i nie ma sensu optymalizować modelu dłużej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier\n",
    "\n",
    "#uzupełnij funkcję get_space\n",
    "def get_space(trial): \n",
    "    space = {\"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"n_jobs\": trial.suggest_int(\"n_jobs\", -1, -1)}\n",
    "    return space\n",
    "trials = 3 #liczba prób\n",
    "\n",
    "def objective(trial, model, X, y):\n",
    "    model_space = get_space(trial)\n",
    "\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(mdl, X, y, groups=train_folds, scoring=scoring, cv=GroupKFold(n_splits=len(np.unique(train_folds))), return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 20:18:35,385]\u001b[0m A new study created in memory with name: no-name-e1cecff3-4f7a-44b2-8ce1-1d666134d997\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 20:19:55,852]\u001b[0m Trial 0 finished with value: 0.5475451866834719 and parameters: {'n_estimators': 189, 'max_depth': 19, 'min_samples_split': 18, 'n_jobs': -1}. Best is trial 0 with value: 0.5475451866834719.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 20:20:07,292]\u001b[0m Trial 1 finished with value: 0.4995501158510172 and parameters: {'n_estimators': 31, 'max_depth': 7, 'min_samples_split': 4, 'n_jobs': -1}. Best is trial 0 with value: 0.5475451866834719.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 20:20:35,950]\u001b[0m Trial 2 finished with value: 0.5195347130730005 and parameters: {'n_estimators': 105, 'max_depth': 8, 'min_samples_split': 16, 'n_jobs': -1}. Best is trial 0 with value: 0.5475451866834719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18.2 s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%%time to komenda służąca do pomiaru czasu wykonywania komórki, musi znajdować się na samej górze komórki\n",
    "study.optimize(lambda x: objective(x, model, X_train, y_train), n_trials=trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbd936b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 189, 'max_depth': 19, 'min_samples_split': 18, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "params = study.best_params\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  0 10  0  1 31  0  1  5]\n",
      " [ 0  0  6  0  2  2  1  0  5]\n",
      " [ 0  0 84  2  0  2  0  1  9]\n",
      " [ 2  0 11 45  0  0  0  1  9]\n",
      " [ 0  0  5  3 43 24  0  5  4]\n",
      " [ 7  0  1  0  1 70  1  0  9]\n",
      " [ 1  0  0  0  4  0 68  0  0]\n",
      " [ 0  0 37  0  2  0  0 36  2]\n",
      " [ 0  0 12  1  2  0  0  3 82]]\n",
      "0.6808510638297872\n"
     ]
    }
   ],
   "source": [
    "#Wytrenuj model o najlepszych hiperparametrach, przeprowadź predykcję i wylicz metryki\n",
    "\n",
    "#clf_both_best = RandomForestClassifier(random_state=42, n_estimators=params[0], max_depth=params[1], min_samples_split=params[2], n_jobs=params[3])\n",
    "clf_both_best = RandomForestClassifier(random_state=42, **params)\n",
    "clf_both_best.fit(X_train_both, y_train)\n",
    "both_preds_best = clf_both_best.predict(X_test_both)\n",
    "print(confusion_matrix(y_test, both_preds_best))\n",
    "print(accuracy_score(y_test,both_preds_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czy wyniki uzyskane przy użyciu optymalizowanego modelu są lepsze, niż te, które uzyskaliśmy stosując domyślne wartości hiperparametrów?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRA TREES\n",
    "\n",
    "Algorytmem bardzo podobnym do lasu losowego jest algorytm ExtraTrees. Od lasu losowego różni go przede wszystkich kryterium podziału drzewa w danym węźle: w ExtraTrees kryterium jest losowe, a w lasach losowych stosowane jest kryterium optymalne (dające najlepszy podział). Dzięki temu algorytm ExtraTrees zazwyczaj jest szybszy. Kolejną istotną różnicą jest to, że podczas podziału danych w lesie losowym stosowane jest tzw. losowanie ze zwracaniem, natomiast w ExtraTrees nie - oznacza to, że w ExtraTrees obserwacje podane do kolejnych drzew nie będą się powtarzać, natomiast w lesie losowym mogą.\n",
    "\n",
    "ExtraTrees najczęściej daje (trochę) gorsze wyniki niż las losowy, jednak nie zawsze tak jest - jeżeli mamy czas, warto wypróbować oba algorytmy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier\n",
    "\n",
    "#uzupełnij funkcję get_space\n",
    "def get_space(trial): \n",
    "    space = {\"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"n_jobs\": trial.suggest_int(\"n_jobs\", -1, -1)}\n",
    "    return space\n",
    "trials = 3 #liczba prób\n",
    "\n",
    "def objective(trial, model, X, y):\n",
    "    model_space = get_space(trial)\n",
    "\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(mdl, X, y, groups=train_folds, scoring=scoring, cv=GroupKFold(n_splits=len(np.unique(train_folds))), return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 20:35:17,837]\u001b[0m A new study created in memory with name: no-name-a9ce7fcd-1297-48e6-91ef-ef0ac165ebdb\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 20:35:38,003]\u001b[0m Trial 0 finished with value: 0.5384231945959664 and parameters: {'n_estimators': 46, 'max_depth': 15, 'min_samples_split': 3, 'n_jobs': -1}. Best is trial 0 with value: 0.5384231945959664.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 20:35:53,876]\u001b[0m Trial 1 finished with value: 0.5572924272271176 and parameters: {'n_estimators': 84, 'max_depth': 18, 'min_samples_split': 10, 'n_jobs': -1}. Best is trial 1 with value: 0.5572924272271176.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 20:36:08,651]\u001b[0m Trial 2 finished with value: 0.46449491834946394 and parameters: {'n_estimators': 78, 'max_depth': 4, 'min_samples_split': 12, 'n_jobs': -1}. Best is trial 1 with value: 0.5572924272271176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20.2 s\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study.optimize(lambda x: objective(x, model, X_train, y_train), n_trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 84, 'max_depth': 18, 'min_samples_split': 10, 'n_jobs': -1}\n",
      "[[52  0  7  0  2 31  1  0  7]\n",
      " [ 0  0  8  0  0  2  0  0  6]\n",
      " [ 0  0 84  3  0  1  0  1  9]\n",
      " [ 1  0 13 45  0  0  0  2  7]\n",
      " [ 2  0 12  1 54  5  1  3  6]\n",
      " [13  0  3  0  0 50 15  0  8]\n",
      " [ 1  0  0  0 11  0 61  0  0]\n",
      " [ 0  0 36  0  1  0  3 36  1]\n",
      " [ 0  0 12  0  0  0  1  3 84]]\n",
      "0.6609929078014184\n"
     ]
    }
   ],
   "source": [
    "#Wytrenuj model o najlepszych hiperparametrach, przeprowadź predykcję i wylicz metryki\n",
    "params = study.best_params\n",
    "print(params)\n",
    "clf_both_best = ExtraTreesClassifier(random_state=42, **params)\n",
    "clf_both_best.fit(X_train_both, y_train)\n",
    "both_preds_best = clf_both_best.predict(X_test_both)\n",
    "print(confusion_matrix(y_test, both_preds_best))\n",
    "print(accuracy_score(y_test,both_preds_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM\n",
    "\n",
    "Ostatnim klasyfikatorem przewidzianym na dzisiaj jest algorytm drzewiasty zaimplementowany w pakiecie LightGBM. W porównaniu do lasów losowych i ExtraTrees cechuje się przede wszystkim większą efektywnością, mniejszym zużyciem pamięci i często pozwala uzyskać większą dokładność klasyfikacji. Ma też o wiele więcej hiperparametrów, które możemy określić lub optymalizować: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "\n",
    "My będziemy optymalizować następujące z nich:\n",
    "- boosting_type - algorytm wzmocnienia gradientowego, zostawimy wartość domyślną, czyli gbdt (Gradient Boosting Decision Tree),\n",
    "- num_leaves - maksymalna liczba liści, które mogą zostać utworzone,\n",
    "- n_estimators - liczba drzew,\n",
    "- max_depth - maksymalna głębokość drzewa (liczba poziomów),\n",
    "- learning_rate - współczynnik określający, z jakim krokiem mają być zmieniane wagi modelu podczas dążenia do osiągnięcia minimalnego błędu popełnianego przez model (zbyt mały learning rate powoduje nadmiernie długi czas uczenia, zbyt duży zwiększa ryzyko \"przeskoczenia\" minimum błędu i nieznalezienia optymalnych wag),\n",
    "- subsample - określa, jaka część obiektów (domyślnie losowanych bez zwracania) ma być podana do drzewa podczas treningu, \n",
    "- colsample_bytree - określa, jaka część wszystkich cech ma być podana do drzewa podczas treningu, \n",
    "- min_child_samples - minimalna liczba obiektów, które muszą znaleźć się w liściu,\n",
    "- min_split_gain - minimalny przyrost informacji, który musi być osiągnięty po podziale węzła (jeżeli nie jest osiągnięty, to węzeł nie będzie dalej dzielony); przyrost informacji definiowany jest jako entropia_przed_podziałem - entropia_po_podziale, gdzie entropia dana jest wzorem:\n",
    "\n",
    "![caption](https://lh6.googleusercontent.com/B4y6fIw_pcAR-AWuTlF5mVlmvKximSRUDhptG-KhvcNLD_RAoITCSi7fn4Owjufm9pnpV3BFrdcijPtA2vCqtSHIPz0Ydrr5NqY924XV-oSl5eOUqfluX9isYXQoU3WHL55x9eLH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier\n",
    "def get_space(trial): \n",
    "    space = {\"boosting_type\": trial.suggest_categorical('boosting_type', [\"gbdt\"]),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 200),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 2, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 200),\n",
    "            \"learning_rate\": trial.suggest_discrete_uniform(\"learning_rate\", 0.00001, 1, 0.0001),\n",
    "            \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.01, 1, 0.01),\n",
    "            \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.01, 1, 0.01),\n",
    "            \"min_split_gain\": trial.suggest_discrete_uniform(\"min_split_gain\", 0.01, 1, 0.01),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 50),\n",
    "            \"n_jobs\": trial.suggest_int(\"n_jobs\", -1, -1)}\n",
    "    return space\n",
    "trials = 3 #liczba prób\n",
    "\n",
    "def objective(trial, model, X, y):\n",
    "    model_space = get_space(trial)\n",
    "\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(mdl, X, y, groups=train_folds, scoring=scoring, cv=GroupKFold(n_splits=len(np.unique(train_folds))), return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba prób powinna być większa niż 60, ale ze względu na brak czasu nie będziemy jej zwiększać. W praktyce korzystając z pakietu LightGBM daje się liczbę prób rzędu kilkuset lub nawet więcej i definiuje się parametr early_stopping_round w którm podaje się, przez ile prób metryka walidacyjna nie ulega poprawie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 20:36:26,629]\u001b[0m A new study created in memory with name: no-name-ff74dbf8-a3d0-440c-8df6-b45c0cc97212\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:7: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_discrete_uniform(\"learning_rate\", 0.00001, 1, 0.0001),\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-05, 1] and step=0.0001, but the range is not divisible by `step`. It will be replaced by [1e-05, 0.99991].\n",
      "  warnings.warn(\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:8: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.01, 1, 0.01),\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:9: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.01, 1, 0.01),\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:10: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"min_split_gain\": trial.suggest_discrete_uniform(\"min_split_gain\", 0.01, 1, 0.01),\n",
      "\u001b[32m[I 2022-12-19 20:36:38,458]\u001b[0m Trial 0 finished with value: 0.4917026268166722 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 19, 'n_estimators': 167, 'max_depth': 167, 'learning_rate': 0.62661, 'subsample': 0.22, 'colsample_bytree': 0.03, 'min_split_gain': 0.19, 'min_child_samples': 40, 'n_jobs': -1}. Best is trial 0 with value: 0.4917026268166722.\u001b[0m\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:7: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_discrete_uniform(\"learning_rate\", 0.00001, 1, 0.0001),\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-05, 1] and step=0.0001, but the range is not divisible by `step`. It will be replaced by [1e-05, 0.99991].\n",
      "  warnings.warn(\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:8: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.01, 1, 0.01),\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:9: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.01, 1, 0.01),\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:10: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"min_split_gain\": trial.suggest_discrete_uniform(\"min_split_gain\", 0.01, 1, 0.01),\n",
      "\u001b[32m[I 2022-12-19 20:37:16,533]\u001b[0m Trial 1 finished with value: 0.16807717473350706 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 160, 'n_estimators': 19, 'max_depth': 74, 'learning_rate': 0.58261, 'subsample': 0.28, 'colsample_bytree': 0.91, 'min_split_gain': 0.55, 'min_child_samples': 10, 'n_jobs': -1}. Best is trial 0 with value: 0.4917026268166722.\u001b[0m\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:7: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_discrete_uniform(\"learning_rate\", 0.00001, 1, 0.0001),\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-05, 1] and step=0.0001, but the range is not divisible by `step`. It will be replaced by [1e-05, 0.99991].\n",
      "  warnings.warn(\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:8: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.01, 1, 0.01),\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:9: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.01, 1, 0.01),\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_12420\\54684782.py:10: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"min_split_gain\": trial.suggest_discrete_uniform(\"min_split_gain\", 0.01, 1, 0.01),\n",
      "\u001b[32m[I 2022-12-19 20:37:35,566]\u001b[0m Trial 2 finished with value: 0.16660647043315788 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 166, 'n_estimators': 46, 'max_depth': 177, 'learning_rate': 0.89031, 'subsample': 0.44, 'colsample_bytree': 0.4, 'min_split_gain': 0.08, 'min_child_samples': 3, 'n_jobs': -1}. Best is trial 0 with value: 0.4917026268166722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:  {'boosting_type': 'gbdt', 'num_leaves': 19, 'n_estimators': 167, 'max_depth': 167, 'learning_rate': 0.62661, 'subsample': 0.22, 'colsample_bytree': 0.03, 'min_split_gain': 0.19, 'min_child_samples': 40, 'n_jobs': -1}\n",
      "CPU times: total: 2min 17s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study.optimize(lambda x: objective(x, model, X_train, y_train), n_trials=trials)\n",
    "print('params: ', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'num_leaves': 19, 'n_estimators': 167, 'max_depth': 167, 'learning_rate': 0.62661, 'subsample': 0.22, 'colsample_bytree': 0.03, 'min_split_gain': 0.19, 'min_child_samples': 40, 'n_jobs': -1}\n",
      "[[54  0 13  0  1 26  2  2  2]\n",
      " [ 1  3  5  0  1  2  0  1  3]\n",
      " [ 3  0 79  6  0  2  0  2  6]\n",
      " [ 0  0  8 50  0  0  0  1  9]\n",
      " [ 4  1  7  5 49  5  2  5  6]\n",
      " [ 9  0  1  0  2 65  4  0  8]\n",
      " [ 1  0  0  0 15  1 55  1  0]\n",
      " [ 4  1 25  2  0  0  0 44  1]\n",
      " [ 1  2  7  2  3  1  2  5 77]]\n",
      "0.675177304964539\n"
     ]
    }
   ],
   "source": [
    "#Wytrenuj model o najlepszych hiperparametrach, przeprowadź predykcję i wylicz metryki\n",
    "params = study.best_params\n",
    "print(params)\n",
    "clf_both_best_LGBM = lgb.LGBMClassifier(random_state=42, **params)\n",
    "clf_both_best_LGBM.fit(X_train_both, y_train)\n",
    "both_preds_best = clf_both_best_LGBM.predict(X_test_both)\n",
    "print(confusion_matrix(y_test, both_preds_best))\n",
    "print(accuracy_score(y_test,both_preds_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównaj uzyskane wszystkimi metodami macierze pomyłek. Która klasa jest najczęściej źle klasyfikowna, bez względu na użyty model? Jak myślisz, dlaczego?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947552fc",
   "metadata": {},
   "source": [
    "Najczęściej elementy są błędnie klasyfikowane do ostatniego zbioru. Prawdopodobnie jest to spowodowane tym, że w zbiorze uczącym nie ma elementów tej klasy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "003d2ed0251cf1f53a8f82a49259dd5eaea3cfae8763dd6d1b9e2eee77f1dc18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
