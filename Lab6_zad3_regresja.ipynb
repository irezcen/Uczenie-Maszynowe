{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W zadaniu 1 regresja służyła de facto do przeprowadzenia klasyfikacji. Modele regresyjne mają też jednak inne zastosowanie - można przy ich użyciu przewidywać wartości ciągłe. W tym celu w wektorze y nie zawieramy klas, tylko wartości jakiegoś parametru lub wielkości fizycznej, które mogą zmieniać się w sposób ciągły i uzależnione są od wartości zmiennych niezależnych (opisujących obiekt). Nauczony model ma za zadanie przewidzieć, jaka wartość pojawi się w zmiennej y, jeżeli na wejściu dostanie ciąg opisujących obiekt cech.\n",
    "\n",
    "Przykładowy model regresyjny posłuży nam do wyznaczania, jaka jest częstotliwość tonu podstawowego (F0) głosu w nagraniach samogłosek o przedłużonej fonacji emitowanyc na różnej wysokości.\n",
    "\n",
    "W wektorze X znajdują się cechy wyekstrahowane przy użyciu biblioteki opensmile, w wektorze y - wartości F0 w danym nagraniu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(909,)\n"
     ]
    }
   ],
   "source": [
    "#wczytywanie danych\n",
    "X = np.load('opensmile_feats.npy') #macierz cech - jednej wiersz = jeden obiekt\n",
    "y = np.load('fundamental_frequencies.npy') #labele\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) #podział na zbiory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train) #standaryzacja\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ liczba cech jest duża, regresor albo trenowałby się długo, albo w ogóle nie byłby w stanie poprawnie nauczyć się określać F0. By rozwiązać ten problem, zaczniemy od redukcji wymiarowości - przeprowadź redukcję funkcją SelectKBest.\n",
    "\n",
    "Liczba cech, którą należy uzyskać po redukcji jest już określona i została dobrana losowo - jej optymalizacja będzie na końcu zadania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "liczba_cech = 100\n",
    "selecter = SelectKBest(score_func=f_regression, k=liczba_cech)\n",
    "X_train_dim_reduced = selecter.fit_transform(X_train_scaled, y_train)\n",
    "X_test_dim_reduced = selecter.fit_transform(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po redukcji wymiarowości możemy przystąpić do uczenia modelu i predykcji. W wyniku predykcji powinniśmy dostać wartości F0, które wg modelu odpowiadają analizowanym nagraniom.\n",
    "\n",
    "Użyjemy algorytmu BayesianRidge, który jest dość podobny do klasycznej regresji liniowej. Różnica jest taka, że w regresji liniowej współczynniki przy kolejnych składowych (odpowiadających zmiennym zależnym) wyrażone są konkretną wartością liczbową, natomiast w regresji bayesowskiej estymuje się rozkłady prawdopodobieństwa tych współczynników. Ponadto, ponieważ jest to regresja typu ridge, to wykorzystuje normę L2 podczas regularyzacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X_train_dim_reduced, X_test_dim_reduced - macierze cech po redukcji wymiarowości\n",
    "ridge_reg = BayesianRidge()\n",
    "ridge_reg.fit(X_train_dim_reduced, y_train)\n",
    "preds_test = ridge_reg.predict(X_test_dim_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Średni błąd bezwględny (MAE) wylicza się jako średnią wartość |y_test - preds_test|. Im mniejsza wartość MAE, tym lepsze predykcje.\n",
    "\n",
    "Uzyskana wartość MAE może być interpretowana jako średnia liczba Hz, o jaką pomylił się regresor przewidując F0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.47045735182812\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model można zoptymalizować, żeby uzyskać lepsze wyniki. Należy zmienić metrykę, która będzie wykorzystywana do oceny modelu podczas optymalizacji, czyli scoring. Ponadto trzeba zmienić direction='maximize' na direction='minimize', ponieważ tym razem zależy nam na jak najmniejszej wartości metryki, a nie jak największej. Powinniśmy również zmienić StratifiedKFold na KFold, ponieważ stratyfikacja ma sens tylko w zadaniu klasyfikacyjnym.\n",
    "\n",
    "Pozostały kod powinien wyglądać analogicznie jak w poprzednich zadaniach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'mae': make_scorer(mean_absolute_error)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial, model, space, X, y):\n",
    "    model_space = get_space(trial)\n",
    "\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(mdl, X, y, scoring=scoring, cv=KFold(n_splits=5), return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametry, które należy zoptymalizować i powinny znaleźć się w funkcji get_space to:\n",
    "- alpha_1\n",
    "- alpha_2\n",
    "- lambda_1\n",
    "- lambda_2\n",
    "\n",
    "Wszystkie powinny przyjmować wartości ciągłe z przedziału [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianRidge\n",
    "def get_space(trial):\n",
    "    space =  {\"alpha_1\": trial.suggest_float('alpha_1', 0.0000001, 0.0001),\n",
    "            \"alpha_2\": trial.suggest_float('alpha_2', 0.0000001, 0.0001),\n",
    "            \"lambda_1\": trial.suggest_float('lambda_1', 0.0000001, 0.0001),\n",
    "            \"lambda_2\": trial.suggest_float('lambda_2', 0.0000001, 0.0001)}\n",
    "    return space\n",
    "trials = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początku najlepiej pracować na małej liczbie triali - jak kod już zadziała, trzeba będzie ją zwiększyć. 5 prób to za mało, żeby uzyskać dobre wyniki przy optymalizacji kilku hiperparametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 22:26:52,968]\u001b[0m A new study created in memory with name: no-name-2a747b57-86a0-4381-8180-0e9d85b7a09a\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:53,162]\u001b[0m Trial 0 finished with value: 35.55002750745494 and parameters: {'alpha_1': 9.563923945476126e-05, 'alpha_2': 3.415930780980981e-05, 'lambda_1': 8.709620120553179e-05, 'lambda_2': 2.6166461454453323e-06}. Best is trial 0 with value: 35.55002750745494.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:53,369]\u001b[0m Trial 1 finished with value: 35.55002765914025 and parameters: {'alpha_1': 7.832963917903754e-05, 'alpha_2': 6.0830328706319114e-05, 'lambda_1': 5.280873021634457e-05, 'lambda_2': 4.3318833017603926e-05}. Best is trial 0 with value: 35.55002750745494.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:53,581]\u001b[0m Trial 2 finished with value: 35.55002770128171 and parameters: {'alpha_1': 1.0402188845213296e-05, 'alpha_2': 1.2129754924236187e-05, 'lambda_1': 3.711885190188406e-05, 'lambda_2': 7.735334130297255e-05}. Best is trial 0 with value: 35.55002750745494.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:53,825]\u001b[0m Trial 3 finished with value: 35.55002772213169 and parameters: {'alpha_1': 6.942266977821385e-05, 'alpha_2': 2.320528804571927e-06, 'lambda_1': 3.847077534904329e-05, 'lambda_2': 7.106198681094556e-05}. Best is trial 0 with value: 35.55002750745494.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:54,026]\u001b[0m Trial 4 finished with value: 35.55002769949594 and parameters: {'alpha_1': 4.057203630747385e-05, 'alpha_2': 9.813944902561982e-06, 'lambda_1': 4.032896320988849e-05, 'lambda_2': 4.7278516925542265e-05}. Best is trial 0 with value: 35.55002750745494.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:54,193]\u001b[0m Trial 5 finished with value: 35.55002763045931 and parameters: {'alpha_1': 6.601361936990747e-05, 'alpha_2': 5.4120012456431174e-05, 'lambda_1': 5.7805182113866616e-05, 'lambda_2': 4.6852669934048284e-05}. Best is trial 0 with value: 35.55002750745494.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:54,361]\u001b[0m Trial 6 finished with value: 35.55002743241555 and parameters: {'alpha_1': 9.398534224729562e-06, 'alpha_2': 5.5818117650965853e-05, 'lambda_1': 9.524347513774944e-05, 'lambda_2': 8.6231192077026e-05}. Best is trial 6 with value: 35.55002743241555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:54,527]\u001b[0m Trial 7 finished with value: 35.55002787598644 and parameters: {'alpha_1': 5.744727384362458e-05, 'alpha_2': 4.189685304484495e-05, 'lambda_1': 4.119448620295582e-06, 'lambda_2': 9.2052685692399e-05}. Best is trial 6 with value: 35.55002743241555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:54,706]\u001b[0m Trial 8 finished with value: 35.550027515055106 and parameters: {'alpha_1': 9.508387723307383e-05, 'alpha_2': 7.154005924852488e-05, 'lambda_1': 8.581516450556744e-05, 'lambda_2': 6.784801585122321e-05}. Best is trial 6 with value: 35.55002743241555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:54,961]\u001b[0m Trial 9 finished with value: 35.550027720523524 and parameters: {'alpha_1': 9.919496683235612e-05, 'alpha_2': 8.188469532897825e-05, 'lambda_1': 4.134925682966488e-05, 'lambda_2': 2.2032914249651555e-06}. Best is trial 6 with value: 35.55002743241555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:55,258]\u001b[0m Trial 10 finished with value: 35.55002740759606 and parameters: {'alpha_1': 2.764471367000136e-06, 'alpha_2': 9.802976037105732e-05, 'lambda_1': 9.998279160117151e-05, 'lambda_2': 9.165240757965775e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:55,561]\u001b[0m Trial 11 finished with value: 35.55002741022676 and parameters: {'alpha_1': 1.882824053870034e-06, 'alpha_2': 9.500768699739804e-05, 'lambda_1': 9.936183358314882e-05, 'lambda_2': 9.727594552909429e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:55,827]\u001b[0m Trial 12 finished with value: 35.55002750391019 and parameters: {'alpha_1': 2.6821669089856524e-05, 'alpha_2': 9.637817610860397e-05, 'lambda_1': 8.159533453687613e-05, 'lambda_2': 9.847162950022628e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:56,111]\u001b[0m Trial 13 finished with value: 35.5500275437722 and parameters: {'alpha_1': 1.5280407636128901e-06, 'alpha_2': 9.638690743547395e-05, 'lambda_1': 6.997299711067453e-05, 'lambda_2': 2.5798947869852174e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:56,417]\u001b[0m Trial 14 finished with value: 35.550027419299006 and parameters: {'alpha_1': 2.5492698760978535e-05, 'alpha_2': 8.251533176637002e-05, 'lambda_1': 9.955764265880043e-05, 'lambda_2': 6.57279656733216e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:56,724]\u001b[0m Trial 15 finished with value: 35.55002755351694 and parameters: {'alpha_1': 2.4805006631726713e-05, 'alpha_2': 7.900588605617379e-05, 'lambda_1': 7.066652510151486e-05, 'lambda_2': 9.919049313619855e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:57,011]\u001b[0m Trial 16 finished with value: 35.55002782634015 and parameters: {'alpha_1': 4.2179535650715634e-05, 'alpha_2': 9.9138859810453e-05, 'lambda_1': 1.3265394220561484e-05, 'lambda_2': 8.183920000124042e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:57,331]\u001b[0m Trial 17 finished with value: 35.550027556122075 and parameters: {'alpha_1': 1.5427986469003475e-05, 'alpha_2': 8.647161710222908e-05, 'lambda_1': 6.891876495833469e-05, 'lambda_2': 6.10267507572551e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:57,733]\u001b[0m Trial 18 finished with value: 35.55002750430453 and parameters: {'alpha_1': 2.190478824484334e-06, 'alpha_2': 6.666711925901308e-05, 'lambda_1': 7.861228838191833e-05, 'lambda_2': 3.0902594366254724e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:58,006]\u001b[0m Trial 19 finished with value: 35.55002742411799 and parameters: {'alpha_1': 3.842430566562212e-05, 'alpha_2': 2.7387970873918238e-05, 'lambda_1': 9.993922837380765e-05, 'lambda_2': 8.56582403341992e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:58,264]\u001b[0m Trial 20 finished with value: 35.55002759300917 and parameters: {'alpha_1': 1.7464778872767552e-05, 'alpha_2': 8.978010539504919e-05, 'lambda_1': 6.123996172108226e-05, 'lambda_2': 7.626516270560852e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:58,561]\u001b[0m Trial 21 finished with value: 35.55002745129633 and parameters: {'alpha_1': 2.8027594041405545e-05, 'alpha_2': 7.353350370351771e-05, 'lambda_1': 9.284389398344606e-05, 'lambda_2': 5.873988122823029e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:58,835]\u001b[0m Trial 22 finished with value: 35.550027443577356 and parameters: {'alpha_1': 1.1391729214572406e-06, 'alpha_2': 9.09988467983737e-05, 'lambda_1': 9.20310850641888e-05, 'lambda_2': 9.089245588522255e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:59,141]\u001b[0m Trial 23 finished with value: 35.55002741491948 and parameters: {'alpha_1': 1.935211142184928e-05, 'alpha_2': 8.149256558079435e-05, 'lambda_1': 9.984948899675785e-05, 'lambda_2': 5.928104144331236e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:59,409]\u001b[0m Trial 24 finished with value: 35.550027521036256 and parameters: {'alpha_1': 1.1250962163918113e-05, 'alpha_2': 7.492820091846108e-05, 'lambda_1': 7.58693656872785e-05, 'lambda_2': 2.642768586769647e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:59,676]\u001b[0m Trial 25 finished with value: 35.55002775935346 and parameters: {'alpha_1': 1.853846853182616e-05, 'alpha_2': 9.986472095400477e-05, 'lambda_1': 2.5220985561106087e-05, 'lambda_2': 5.5033952040693954e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:26:59,980]\u001b[0m Trial 26 finished with value: 35.5500274710471 and parameters: {'alpha_1': 3.32839867767407e-05, 'alpha_2': 8.846875840860699e-05, 'lambda_1': 8.895854057005562e-05, 'lambda_2': 3.7427009367259016e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:27:00,255]\u001b[0m Trial 27 finished with value: 35.55002751380975 and parameters: {'alpha_1': 4.934710316961848e-05, 'alpha_2': 9.154771048297047e-05, 'lambda_1': 8.167840518923213e-05, 'lambda_2': 9.408515828511079e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:27:00,576]\u001b[0m Trial 28 finished with value: 35.550027418822125 and parameters: {'alpha_1': 6.772822171380743e-06, 'alpha_2': 6.532094679917414e-05, 'lambda_1': 9.746140087435118e-05, 'lambda_2': 1.4857512290877285e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n",
      "\u001b[32m[I 2022-12-19 22:27:00,860]\u001b[0m Trial 29 finished with value: 35.550027479455736 and parameters: {'alpha_1': 1.9924102812387097e-05, 'alpha_2': 8.043664913662748e-05, 'lambda_1': 8.605974211241897e-05, 'lambda_2': 7.719302196362125e-05}. Best is trial 10 with value: 35.55002740759606.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda x: objective(x, model, get_space, X_train_dim_reduced, y_train), n_trials=trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powtórz optymalizację zmieniając metrykę z MAE na błąd średniokwadratowy MSE (mean_squared_error). Czy wyniki różnią się? Jak myślisz, różniłyby się, gdyby liczba triali była większa, czy powinny zbiegać do tej samej wartości?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:  {'alpha_1': 2.764471367000136e-06, 'alpha_2': 9.802976037105732e-05, 'lambda_1': 9.998279160117151e-05, 'lambda_2': 9.165240757965775e-05}\n",
      "test MAE:  85.47032063522393\n",
      "test MSE:  10036.970005818124\n"
     ]
    }
   ],
   "source": [
    "print('params: ', study.best_params)\n",
    "\n",
    "ridge_reg = model(**study.best_params)\n",
    "ridge_reg.fit(X_train_dim_reduced, y_train)\n",
    "preds = ridge_reg.predict(X_test_dim_reduced)\n",
    "pickle.dump(ridge_reg, open('ridge_F0_model_mse', 'wb+'))\n",
    "print('test MAE: ', mean_absolute_error(y_test, preds))\n",
    "print('test MSE: ', mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na razie liczba cech wybranych na etapie redukcji wymiarowości wynosi 100 i została wybrana losowo. Spróbuj przeprowadzić optymalizację modelu w taki sposób, by liczba cech też była optymalizowana.\n",
    "\n",
    "Podpowiedź: jeżeli dodasz dodatkowy parametr \"k\" do get_space, to trzeba go będzie usunąć przed utworzeniem modelu w funkcji objective (del model_space[\"k\"]) oraz utworzyć w tej funkcji pipeline, który będzie się składał z selektora SelectKBest o zoptymalizowanej liczbie k oraz z modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model, space, X, y):\n",
    "\n",
    "    model_space = get_space(trial)\n",
    "    k = model_space['k']\n",
    "    del model_space['k']\n",
    "    mdl = make_pipeline(SelectKBest(score_func=f_regression,k=k) , model(**model_space))\n",
    "    scores = cross_validate(mdl, X, y, scoring=scoring, cv=KFold(n_splits=5), return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_mae'])\n",
    "\n",
    "model = BayesianRidge\n",
    "def get_space(trial):\n",
    "    space =  {\"alpha_1\": trial.suggest_float('alpha_1', 0.0000001, 0.0001),\n",
    "            \"alpha_2\": trial.suggest_float('alpha_2', 0.0000001, 0.0001),\n",
    "            \"lambda_1\": trial.suggest_float('lambda_1', 0.0000001, 0.0001),\n",
    "            \"lambda_2\": trial.suggest_float('lambda_2', 0.0000001, 0.0001),\n",
    "            \"k\": trial.suggest_int('k', 10, 1000)}\n",
    "    return space\n",
    "trials = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 22:27:01,157]\u001b[0m A new study created in memory with name: no-name-87307fc1-9607-4b66-991a-3dbe5658672e\u001b[0m\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "\u001b[32m[I 2022-12-19 22:27:01,669]\u001b[0m Trial 0 finished with value: 43.71054994065649 and parameters: {'alpha_1': 7.094227558144413e-05, 'alpha_2': 3.911033234338224e-05, 'lambda_1': 2.444646601597166e-05, 'lambda_2': 5.056918558039816e-06, 'k': 21}. Best is trial 0 with value: 43.71054994065649.\u001b[0m\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "\u001b[32m[I 2022-12-19 22:27:02,226]\u001b[0m Trial 1 finished with value: 40.84969837554081 and parameters: {'alpha_1': 1.2812109877622709e-05, 'alpha_2': 2.2568730162084662e-05, 'lambda_1': 7.706041680050157e-05, 'lambda_2': 5.5012060344584426e-05, 'k': 31}. Best is trial 1 with value: 40.84969837554081.\u001b[0m\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "\u001b[32m[I 2022-12-19 22:27:07,172]\u001b[0m Trial 2 finished with value: 25.521994439380563 and parameters: {'alpha_1': 5.0202817745971345e-05, 'alpha_2': 5.2417119821286434e-05, 'lambda_1': 2.63103103394604e-05, 'lambda_2': 8.11466238687345e-05, 'k': 980}. Best is trial 2 with value: 25.521994439380563.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda x: objective(x, model, get_space, X_train_scaled, y_train), n_trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:  {'alpha_1': 5.0202817745971345e-05, 'alpha_2': 5.2417119821286434e-05, 'lambda_1': 2.63103103394604e-05, 'lambda_2': 8.11466238687345e-05}\n",
      "test MAE:  24.24503464225252\n",
      "test MSE:  1070.2719231778497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = study.best_params['k']\n",
    "params = study.best_params\n",
    "del params['k']\n",
    "print('params: ', params)\n",
    "ridge_reg = make_pipeline(SelectKBest(score_func=f_regression, k=k) , model(**params))\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "preds = ridge_reg.predict(X_test_scaled)\n",
    "pickle.dump(ridge_reg, open('ridge_F0_model_mse', 'wb+'))\n",
    "print('test MAE: ', mean_absolute_error(y_test, preds))\n",
    "print('test MSE: ', mean_squared_error(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0cf854484826becf69b9363a35f769a3f32573db803431254cc95fc20fb81b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
